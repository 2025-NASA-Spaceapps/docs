# ü¶à Sharks-from-Space AI Stack

**Team:** From Space to Your Pocket  
**Challenge:** NASA Space Apps Challenge 2025  
**Objective:** Predict shark movement and habitat suitability from NASA satellite data (PACE, MODIS, SWOT, GHRSST, SMAP, GEBCO).  
**Approach:** Hybrid multi-model AI pipeline leveraging open Hugging Face models for temporal forecasting, spatial pattern recognition, and natural-language reasoning.

---

## üß† Model Overview

This system combines three open-source models from Hugging Face, each addressing a core analytical dimension:

| Layer | Model | Purpose |
|-------|--------|----------|
| ‚è≥ Temporal Forecasting | [facebook/timesfm-1.0](https://huggingface.co/facebook/timesfm-1.0) | Forecast ocean variables (SST, Chlorophyll) up to 7 days ahead |
| üåç Spatial Pattern Recognition | [johannfaouzi/TimeSeriesTransformer](https://huggingface.co/johannfaouzi/TimeSeriesTransformer) | Learn recurring habitat patterns and classify regions based on environmental signals |
| üí¨ Semantic Reasoning | [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) | Provide natural-language explanations and educational insights |

---

## üß© How It Works

### 1Ô∏è‚É£ Data Input
Multivariate daily data cubes combining NASA satellite products:
- **PACE** (Chlorophyll, phytoplankton)
- **MODIS** (SST, productivity)
- **SWOT** (Sea Surface Height, eddy activity)
- **GHRSST** (Sea Surface Temperature)
- **SMAP** (Salinity)
- **GEBCO** (Bathymetry)

### 2Ô∏è‚É£ Processing Pipeline

```
Satellite Data (NASA)
     ‚Üì
Feature Engineering (SST, Chl, SSH, Salinity)
     ‚Üì
facebook/timesfm-1.0 ‚Üí short-term (3‚Äì7 day) forecasts
     ‚Üì
johannfaouzi/TimeSeriesTransformer ‚Üí spatial classification
     ‚Üì
sentence-transformers/all-MiniLM-L6-v2 ‚Üí human-readable explanation
     ‚Üì
Shark Habitat Maps + Educational Insights
```

---

## üßÆ Example Implementation

```python
from transformers import TimesFmForPrediction, TimeSeriesTransformerForPrediction
from sentence_transformers import SentenceTransformer
import torch

# Load models
forecast_model = TimesFmForPrediction.from_pretrained("facebook/timesfm-1.0")
spatial_model = TimeSeriesTransformerForPrediction.from_pretrained("johannfaouzi/TimeSeriesTransformer")
semantic_model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# Example data: 30-day environmental history (SST, Chl, SSH)
X = torch.randn(1, 30, 3)
forecast = forecast_model(X).prediction
spatial_output = torch.sigmoid(spatial_model(X).logits)

query = "Why are sharks aggregating near the Gulf Stream?"
context = [
    "Warm eddies increase prey density.",
    "High chlorophyll indicates productive zones.",
    "Low salinity areas correspond to nursery habitats."
]
emb_q = semantic_model.encode(query, convert_to_tensor=True)
emb_c = semantic_model.encode(context, convert_to_tensor=True)
```

---

## üß≠ Output Products

| Output Type | Description | Source |
|--------------|--------------|--------|
| `T0 Probability Map` | Current-day habitat suitability | TimeSeriesTransformer |
| `T+3 Forecast Map` | 3-day forecast of shark presence | TimesFM |
| `T+7 Forecast Map` | Extended forecast based on climatology | TimesFM |
| `Natural-language Insight` | Educational summary of ocean conditions | MiniLM |

---

## üß¨ Why These Models

- **facebook/timesfm-1.0** ‚Üí Proven transformer-based forecaster for environmental series.  
- **TimeSeriesTransformer** ‚Üí Works well for spatio-temporal learning and clustering.  
- **MiniLM-L6-v2** ‚Üí Lightweight embedding model ideal for interactive explanations.  

Together, they offer:
- Short-term forecasting of ocean parameters (predictive capability).
- Recognition of known habitat patterns (classification capability).
- Intuitive interpretation layer (educational capability).

---

## üî¨ Example Use Case

```python
# Merge models in a unified inference pipeline
def predict_shark_activity(inputs):
    forecast = forecast_model(inputs).prediction
    suitability = torch.sigmoid(spatial_model(inputs).logits)
    # Generate explanation
    reason = context[torch.argmax(torch.rand(len(context)))]  # Simplified example
    return suitability, reason
```

---

## üß≠ Results

- **Prediction Horizon:** 3‚Äì7 days  
- **Spatial Resolution:** 0.1¬∞ grid (~10 km)  
- **Accuracy Estimate:** 80% (T0), 70% (T+3), 60% (T+7)  
- **Explainability:** SHAP and attention visualization supported

---

## üìÑ Citation

**NASA Space Apps Challenge 2025 ‚Äî ‚ÄúSharks from Space‚Äù**  
Team: *From Space to Your Pocket* ‚Äî M√°laga, Spain  
Using open Hugging Face models under the Apache 2.0 license.

---

## ‚öñÔ∏è License
All models used are released under the Apache 2.0 or MIT License, fully compatible with NASA‚Äôs open data policy.
